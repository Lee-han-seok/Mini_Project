{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('mpg_X_test.csv')\n",
    "X_train = pd.read_csv('mpg_X_train.csv')\n",
    "y_train = pd.read_csv('mpg_y_train.csv')\n",
    "X_test = X_test.drop(['Unnamed: 0'], axis = 1)\n",
    "X_train = X_train.drop(['Unnamed: 0'], axis = 1)\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pontiac j2000 se hatchback</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2575</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pontiac safari (sw)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5140</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mazda glc custom l</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldsmobile vista cruiser</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4499</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peugeot 504</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3270</td>\n",
       "      <td>21.9</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name   mpg  cylinders  displacement  horsepower  \\\n",
       "0  pontiac j2000 se hatchback  31.0          4         112.0        85.0   \n",
       "1         pontiac safari (sw)  13.0          8         400.0       175.0   \n",
       "2          mazda glc custom l  37.0          4          91.0        68.0   \n",
       "3    oldsmobile vista cruiser  12.0          8         350.0       180.0   \n",
       "4                 peugeot 504  19.0          4         120.0        88.0   \n",
       "\n",
       "   weight  acceleration  model_year  \n",
       "0    2575          16.2          82  \n",
       "1    5140          12.0          71  \n",
       "2    2025          18.2          82  \n",
       "3    4499          12.5          73  \n",
       "4    3270          21.9          76  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head() # X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pontiac j2000 se hatchback</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2575</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pontiac safari (sw)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5140</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mazda glc custom l</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldsmobile vista cruiser</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4499</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peugeot 504</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3270</td>\n",
       "      <td>21.9</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name   mpg  cylinders  displacement  horsepower  \\\n",
       "0  pontiac j2000 se hatchback  31.0          4         112.0        85.0   \n",
       "1         pontiac safari (sw)  13.0          8         400.0       175.0   \n",
       "2          mazda glc custom l  37.0          4          91.0        68.0   \n",
       "3    oldsmobile vista cruiser  12.0          8         350.0       180.0   \n",
       "4                 peugeot 504  19.0          4         120.0        88.0   \n",
       "\n",
       "   weight  acceleration  model_year  \n",
       "0    2575          16.2          82  \n",
       "1    5140          12.0          71  \n",
       "2    2025          18.2          82  \n",
       "3    4499          12.5          73  \n",
       "4    3270          21.9          76  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isUSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isUSA\n",
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   name          278 non-null    object \n",
      " 1   mpg           278 non-null    float64\n",
      " 2   cylinders     278 non-null    int64  \n",
      " 3   displacement  278 non-null    float64\n",
      " 4   horsepower    274 non-null    float64\n",
      " 5   weight        278 non-null    int64  \n",
      " 6   acceleration  278 non-null    float64\n",
      " 7   model_year    278 non-null    int64  \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 17.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   isUSA   278 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn\n",
      "\n",
      "DESCRIPTION\n",
      "    Machine learning module for Python\n",
      "    ==================================\n",
      "    \n",
      "    sklearn is a Python module integrating classical machine\n",
      "    learning algorithms in the tightly-knit world of scientific Python\n",
      "    packages (numpy, scipy, matplotlib).\n",
      "    \n",
      "    It aims to provide simple and efficient solutions to learning problems\n",
      "    that are accessible to everybody and reusable in various contexts:\n",
      "    machine-learning as a versatile tool for science and engineering.\n",
      "    \n",
      "    See http://scikit-learn.org for complete documentation.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __check_build (package)\n",
      "    _build_utils (package)\n",
      "    _config\n",
      "    _distributor_init\n",
      "    _isotonic\n",
      "    _loss (package)\n",
      "    _min_dependencies\n",
      "    base\n",
      "    calibration\n",
      "    cluster (package)\n",
      "    compose (package)\n",
      "    conftest\n",
      "    covariance (package)\n",
      "    cross_decomposition (package)\n",
      "    datasets (package)\n",
      "    decomposition (package)\n",
      "    discriminant_analysis\n",
      "    dummy\n",
      "    ensemble (package)\n",
      "    exceptions\n",
      "    experimental (package)\n",
      "    externals (package)\n",
      "    feature_extraction (package)\n",
      "    feature_selection (package)\n",
      "    gaussian_process (package)\n",
      "    impute (package)\n",
      "    inspection (package)\n",
      "    isotonic\n",
      "    kernel_approximation\n",
      "    kernel_ridge\n",
      "    linear_model (package)\n",
      "    manifold (package)\n",
      "    metrics (package)\n",
      "    mixture (package)\n",
      "    model_selection (package)\n",
      "    multiclass\n",
      "    multioutput\n",
      "    naive_bayes\n",
      "    neighbors (package)\n",
      "    neural_network (package)\n",
      "    pipeline\n",
      "    preprocessing (package)\n",
      "    random_projection\n",
      "    semi_supervised (package)\n",
      "    setup\n",
      "    svm (package)\n",
      "    tests (package)\n",
      "    tree (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clone(estimator, *, safe=True)\n",
      "        Construct a new unfitted estimator with the same parameters.\n",
      "        \n",
      "        Clone does a deep copy of the model in an estimator\n",
      "        without actually copying attached data. It returns a new estimator\n",
      "        with the same parameters that has not been fitted on any data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : {list, tuple, set} of estimator instance or a single             estimator instance\n",
      "            The estimator or group of estimators to be cloned.\n",
      "        safe : bool, default=True\n",
      "            If safe is False, clone will fall back to a deep copy on objects\n",
      "            that are not estimators.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        estimator : object\n",
      "            The deep copy of the input, an estimator if input is an estimator.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If the estimator's `random_state` parameter is an integer (or if the\n",
      "        estimator doesn't have a `random_state` parameter), an *exact clone* is\n",
      "        returned: the clone and the original estimator will give the exact same\n",
      "        results. Otherwise, *statistical clone* is returned: the clone might\n",
      "        return different results from the original estimator. More details can be\n",
      "        found in :ref:`randomness`.\n",
      "    \n",
      "    config_context(*, assume_finite=None, working_memory=None, print_changed_only=None, display=None)\n",
      "        Context manager for global scikit-learn configuration.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, default=None\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error. If None, the existing value won't change.\n",
      "            The default value is False.\n",
      "        \n",
      "        working_memory : int, default=None\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. If None, the existing value won't change.\n",
      "            The default value is 1024.\n",
      "        \n",
      "        print_changed_only : bool, default=None\n",
      "            If True, only the parameters that were set to non-default\n",
      "            values will be printed when printing an estimator. For example,\n",
      "            ``print(SVC())`` while True will only print 'SVC()', but would print\n",
      "            'SVC(C=1.0, cache_size=200, ...)' with all the non-changed parameters\n",
      "            when False. If None, the existing value won't change.\n",
      "            The default value is True.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Default changed from False to True.\n",
      "        \n",
      "        display : {'text', 'diagram'}, default=None\n",
      "            If 'diagram', estimators will be displayed as a diagram in a Jupyter\n",
      "            lab or notebook context. If 'text', estimators will be displayed as\n",
      "            text. If None, the existing value won't change.\n",
      "            The default value is 'text'.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Yields\n",
      "        ------\n",
      "        None.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        set_config : Set global scikit-learn configuration.\n",
      "        get_config : Retrieve current values of the global configuration.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All settings, not just those presently modified, will be returned to\n",
      "        their previous values when the context manager is exited.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import sklearn\n",
      "        >>> from sklearn.utils.validation import assert_all_finite\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     assert_all_finite([float('nan')])\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     with sklearn.config_context(assume_finite=False):\n",
      "        ...         assert_all_finite([float('nan')])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Input contains NaN...\n",
      "    \n",
      "    get_config()\n",
      "        Retrieve current values for configuration set by :func:`set_config`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        config : dict\n",
      "            Keys are parameter names that can be passed to :func:`set_config`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        config_context : Context manager for global scikit-learn configuration.\n",
      "        set_config : Set global scikit-learn configuration.\n",
      "    \n",
      "    set_config(assume_finite=None, working_memory=None, print_changed_only=None, display=None)\n",
      "        Set global scikit-learn configuration\n",
      "        \n",
      "        .. versionadded:: 0.19\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, default=None\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error.  Global default: False.\n",
      "        \n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        working_memory : int, default=None\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. Global default: 1024.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        print_changed_only : bool, default=None\n",
      "            If True, only the parameters that were set to non-default\n",
      "            values will be printed when printing an estimator. For example,\n",
      "            ``print(SVC())`` while True will only print 'SVC()' while the default\n",
      "            behaviour would be to print 'SVC(C=1.0, cache_size=200, ...)' with\n",
      "            all the non-changed parameters.\n",
      "        \n",
      "            .. versionadded:: 0.21\n",
      "        \n",
      "        display : {'text', 'diagram'}, default=None\n",
      "            If 'diagram', estimators will be displayed as a diagram in a Jupyter\n",
      "            lab or notebook context. If 'text', estimators will be displayed as\n",
      "            text. Default is 'text'.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        config_context : Context manager for global scikit-learn configuration.\n",
      "        get_config : Retrieve current values of the global configuration.\n",
      "    \n",
      "    show_versions()\n",
      "        Print useful debugging information\"\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "DATA\n",
      "    __SKLEARN_SETUP__ = False\n",
      "    __all__ = ['calibration', 'cluster', 'covariance', 'cross_decompositio...\n",
      "\n",
      "VERSION\n",
      "    1.0.2\n",
      "\n",
      "FILE\n",
      "    c:\\users\\onest\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\sklearn\\__init__.py\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer # 단순한 NA값 대치가 가능, Simple inputer로 대체허도록 합시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "X_train['horsepower'] = imputer.fit_transform(X_train[['horsepower']])\n",
    "X_test['horsepower'] = imputer.fit_transform(X_test[['horsepower']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODER를 진행할만한 피쳐가 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pontiac j2000 se hatchback</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>112.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2575</td>\n",
       "      <td>16.2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pontiac safari (sw)</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5140</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mazda glc custom l</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oldsmobile vista cruiser</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4499</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peugeot 504</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3270</td>\n",
       "      <td>21.9</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name   mpg  cylinders  displacement  horsepower  \\\n",
       "0  pontiac j2000 se hatchback  31.0          4         112.0        85.0   \n",
       "1         pontiac safari (sw)  13.0          8         400.0       175.0   \n",
       "2          mazda glc custom l  37.0          4          91.0        68.0   \n",
       "3    oldsmobile vista cruiser  12.0          8         350.0       180.0   \n",
       "4                 peugeot 504  19.0          4         120.0        88.0   \n",
       "\n",
       "   weight  acceleration  model_year  \n",
       "0    2575          16.2          82  \n",
       "1    5140          12.0          71  \n",
       "2    2025          18.2          82  \n",
       "3    4499          12.5          73  \n",
       "4    3270          21.9          76  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['name'], axis = 1)\n",
    "X_test = X_test.drop(['name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NUM = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr[COL_NUM] = scaler.transform(X_tr[COL_NUM])\n",
    "X_val[COL_NUM] = scaler.transform(X_val[COL_NUM])\n",
    "X_test[COL_NUM] = scaler.transform(X_test[COL_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn\n",
      "\n",
      "DESCRIPTION\n",
      "    Machine learning module for Python\n",
      "    ==================================\n",
      "    \n",
      "    sklearn is a Python module integrating classical machine\n",
      "    learning algorithms in the tightly-knit world of scientific Python\n",
      "    packages (numpy, scipy, matplotlib).\n",
      "    \n",
      "    It aims to provide simple and efficient solutions to learning problems\n",
      "    that are accessible to everybody and reusable in various contexts:\n",
      "    machine-learning as a versatile tool for science and engineering.\n",
      "    \n",
      "    See http://scikit-learn.org for complete documentation.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __check_build (package)\n",
      "    _build_utils (package)\n",
      "    _config\n",
      "    _distributor_init\n",
      "    _isotonic\n",
      "    _loss (package)\n",
      "    _min_dependencies\n",
      "    base\n",
      "    calibration\n",
      "    cluster (package)\n",
      "    compose (package)\n",
      "    conftest\n",
      "    covariance (package)\n",
      "    cross_decomposition (package)\n",
      "    datasets (package)\n",
      "    decomposition (package)\n",
      "    discriminant_analysis\n",
      "    dummy\n",
      "    ensemble (package)\n",
      "    exceptions\n",
      "    experimental (package)\n",
      "    externals (package)\n",
      "    feature_extraction (package)\n",
      "    feature_selection (package)\n",
      "    gaussian_process (package)\n",
      "    impute (package)\n",
      "    inspection (package)\n",
      "    isotonic\n",
      "    kernel_approximation\n",
      "    kernel_ridge\n",
      "    linear_model (package)\n",
      "    manifold (package)\n",
      "    metrics (package)\n",
      "    mixture (package)\n",
      "    model_selection (package)\n",
      "    multiclass\n",
      "    multioutput\n",
      "    naive_bayes\n",
      "    neighbors (package)\n",
      "    neural_network (package)\n",
      "    pipeline\n",
      "    preprocessing (package)\n",
      "    random_projection\n",
      "    semi_supervised (package)\n",
      "    setup\n",
      "    svm (package)\n",
      "    tests (package)\n",
      "    tree (package)\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clone(estimator, *, safe=True)\n",
      "        Construct a new unfitted estimator with the same parameters.\n",
      "        \n",
      "        Clone does a deep copy of the model in an estimator\n",
      "        without actually copying attached data. It returns a new estimator\n",
      "        with the same parameters that has not been fitted on any data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : {list, tuple, set} of estimator instance or a single             estimator instance\n",
      "            The estimator or group of estimators to be cloned.\n",
      "        safe : bool, default=True\n",
      "            If safe is False, clone will fall back to a deep copy on objects\n",
      "            that are not estimators.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        estimator : object\n",
      "            The deep copy of the input, an estimator if input is an estimator.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If the estimator's `random_state` parameter is an integer (or if the\n",
      "        estimator doesn't have a `random_state` parameter), an *exact clone* is\n",
      "        returned: the clone and the original estimator will give the exact same\n",
      "        results. Otherwise, *statistical clone* is returned: the clone might\n",
      "        return different results from the original estimator. More details can be\n",
      "        found in :ref:`randomness`.\n",
      "    \n",
      "    config_context(*, assume_finite=None, working_memory=None, print_changed_only=None, display=None)\n",
      "        Context manager for global scikit-learn configuration.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, default=None\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error. If None, the existing value won't change.\n",
      "            The default value is False.\n",
      "        \n",
      "        working_memory : int, default=None\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. If None, the existing value won't change.\n",
      "            The default value is 1024.\n",
      "        \n",
      "        print_changed_only : bool, default=None\n",
      "            If True, only the parameters that were set to non-default\n",
      "            values will be printed when printing an estimator. For example,\n",
      "            ``print(SVC())`` while True will only print 'SVC()', but would print\n",
      "            'SVC(C=1.0, cache_size=200, ...)' with all the non-changed parameters\n",
      "            when False. If None, the existing value won't change.\n",
      "            The default value is True.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Default changed from False to True.\n",
      "        \n",
      "        display : {'text', 'diagram'}, default=None\n",
      "            If 'diagram', estimators will be displayed as a diagram in a Jupyter\n",
      "            lab or notebook context. If 'text', estimators will be displayed as\n",
      "            text. If None, the existing value won't change.\n",
      "            The default value is 'text'.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Yields\n",
      "        ------\n",
      "        None.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        set_config : Set global scikit-learn configuration.\n",
      "        get_config : Retrieve current values of the global configuration.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All settings, not just those presently modified, will be returned to\n",
      "        their previous values when the context manager is exited.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import sklearn\n",
      "        >>> from sklearn.utils.validation import assert_all_finite\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     assert_all_finite([float('nan')])\n",
      "        >>> with sklearn.config_context(assume_finite=True):\n",
      "        ...     with sklearn.config_context(assume_finite=False):\n",
      "        ...         assert_all_finite([float('nan')])\n",
      "        Traceback (most recent call last):\n",
      "        ...\n",
      "        ValueError: Input contains NaN...\n",
      "    \n",
      "    get_config()\n",
      "        Retrieve current values for configuration set by :func:`set_config`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        config : dict\n",
      "            Keys are parameter names that can be passed to :func:`set_config`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        config_context : Context manager for global scikit-learn configuration.\n",
      "        set_config : Set global scikit-learn configuration.\n",
      "    \n",
      "    set_config(assume_finite=None, working_memory=None, print_changed_only=None, display=None)\n",
      "        Set global scikit-learn configuration\n",
      "        \n",
      "        .. versionadded:: 0.19\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        assume_finite : bool, default=None\n",
      "            If True, validation for finiteness will be skipped,\n",
      "            saving time, but leading to potential crashes. If\n",
      "            False, validation for finiteness will be performed,\n",
      "            avoiding error.  Global default: False.\n",
      "        \n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        working_memory : int, default=None\n",
      "            If set, scikit-learn will attempt to limit the size of temporary arrays\n",
      "            to this number of MiB (per job when parallelised), often saving both\n",
      "            computation time and memory on expensive operations that can be\n",
      "            performed in chunks. Global default: 1024.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        print_changed_only : bool, default=None\n",
      "            If True, only the parameters that were set to non-default\n",
      "            values will be printed when printing an estimator. For example,\n",
      "            ``print(SVC())`` while True will only print 'SVC()' while the default\n",
      "            behaviour would be to print 'SVC(C=1.0, cache_size=200, ...)' with\n",
      "            all the non-changed parameters.\n",
      "        \n",
      "            .. versionadded:: 0.21\n",
      "        \n",
      "        display : {'text', 'diagram'}, default=None\n",
      "            If 'diagram', estimators will be displayed as a diagram in a Jupyter\n",
      "            lab or notebook context. If 'text', estimators will be displayed as\n",
      "            text. Default is 'text'.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        config_context : Context manager for global scikit-learn configuration.\n",
      "        get_config : Retrieve current values of the global configuration.\n",
      "    \n",
      "    show_versions()\n",
      "        Print useful debugging information\"\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "\n",
      "DATA\n",
      "    __SKLEARN_SETUP__ = False\n",
      "    __all__ = ['calibration', 'cluster', 'covariance', 'cross_decompositio...\n",
      "\n",
      "VERSION\n",
      "    1.0.2\n",
      "\n",
      "FILE\n",
      "    c:\\users\\onest\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\sklearn\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_tr, y_tr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_tr, y_tr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9725947521865889\n",
      "0.9801749271137026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_rf = rf.predict_proba(X_val)\n",
    "y_pred_xgb = xgb.predict_proba(X_val)\n",
    "\n",
    "score_rf = roc_auc_score(y_val, y_pred_rf[:,1])\n",
    "score_xgb = roc_auc_score(y_val, y_pred_xgb[:,1])\n",
    "\n",
    "print(score_rf)\n",
    "print(score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00533293, 0.9742517 , 0.9907392 , 0.9957759 , 0.04123505,\n",
       "       0.00991186, 0.02625613, 0.04745476, 0.75860524, 0.01816236,\n",
       "       0.9903054 , 0.03014123, 0.9960598 , 0.00308642, 0.0300068 ,\n",
       "       0.06108641, 0.9960598 , 0.98684675, 0.00904101, 0.99684095,\n",
       "       0.99494004, 0.99721235, 0.9960598 , 0.9960598 , 0.9960598 ,\n",
       "       0.00601467, 0.00677658, 0.9962676 , 0.99291515, 0.9151431 ,\n",
       "       0.714659  , 0.00420868, 0.30505008, 0.32417795, 0.99329424,\n",
       "       0.44000643, 0.9311791 , 0.9972832 , 0.8765071 , 0.9822046 ,\n",
       "       0.9960598 , 0.00677658, 0.03739977, 0.8139705 , 0.0992803 ,\n",
       "       0.920484  , 0.05479553, 0.99582255, 0.01042202, 0.9806928 ,\n",
       "       0.7815507 , 0.0028555 , 0.99329424, 0.36988574, 0.99582255,\n",
       "       0.98684675, 0.99665064, 0.9000458 , 0.9977125 , 0.00979401,\n",
       "       0.69314325, 0.640038  , 0.9960598 , 0.9903054 , 0.9881491 ,\n",
       "       0.9925454 , 0.98684675, 0.12401452, 0.7806238 , 0.0028555 ,\n",
       "       0.9906234 , 0.9938431 , 0.9951999 , 0.01570152, 0.99582255,\n",
       "       0.07185936, 0.9907392 , 0.08720196, 0.01030297, 0.98684675,\n",
       "       0.9962786 , 0.98684675, 0.00111575, 0.9822703 , 0.9960598 ,\n",
       "       0.9927648 , 0.00490693, 0.02448423, 0.06644291, 0.9928918 ,\n",
       "       0.99329424, 0.9960598 , 0.9960598 , 0.99582255, 0.99651426,\n",
       "       0.9842981 , 0.02772479, 0.9903054 , 0.9960598 , 0.99565923,\n",
       "       0.99900347, 0.9960598 , 0.9960598 , 0.98684675, 0.99817276,\n",
       "       0.01325612, 0.02318311, 0.99620134, 0.0026901 , 0.99582255,\n",
       "       0.29275614, 0.9962786 , 0.0076281 , 0.99064285, 0.9903054 ,\n",
       "       0.02115381, 0.9938431 , 0.99665064, 0.9907392 , 0.02231754],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.94667053e-01, 2.57483125e-02, 9.26077366e-03, 4.22412157e-03,\n",
       "       9.58764970e-01, 9.90088165e-01, 9.73743856e-01, 9.52545226e-01,\n",
       "       2.41394758e-01, 9.81837630e-01, 9.69457626e-03, 9.69858766e-01,\n",
       "       3.94022465e-03, 9.96913552e-01, 9.69993174e-01, 9.38913584e-01,\n",
       "       3.94022465e-03, 1.31532550e-02, 9.90958989e-01, 3.15904617e-03,\n",
       "       5.05995750e-03, 2.78764963e-03, 3.94022465e-03, 3.94022465e-03,\n",
       "       3.94022465e-03, 9.93985295e-01, 9.93223429e-01, 3.73238325e-03,\n",
       "       7.08484650e-03, 8.48569274e-02, 2.85341024e-01, 9.95791316e-01,\n",
       "       6.94949925e-01, 6.75822020e-01, 6.70576096e-03, 5.59993565e-01,\n",
       "       6.88208938e-02, 2.71677971e-03, 1.23492897e-01, 1.77953839e-02,\n",
       "       3.94022465e-03, 9.93223429e-01, 9.62600231e-01, 1.86029494e-01,\n",
       "       9.00719702e-01, 7.95159936e-02, 9.45204496e-01, 4.17745113e-03,\n",
       "       9.89578009e-01, 1.93071961e-02, 2.18449295e-01, 9.97144520e-01,\n",
       "       6.70576096e-03, 6.30114257e-01, 4.17745113e-03, 1.31532550e-02,\n",
       "       3.34936380e-03, 9.99541879e-02, 2.28750706e-03, 9.90206003e-01,\n",
       "       3.06856751e-01, 3.59961987e-01, 3.94022465e-03, 9.69457626e-03,\n",
       "       1.18508935e-02, 7.45457411e-03, 1.31532550e-02, 8.75985503e-01,\n",
       "       2.19376206e-01, 9.97144520e-01, 9.37658548e-03, 6.15692139e-03,\n",
       "       4.80008125e-03, 9.84298468e-01, 4.17745113e-03, 9.28140640e-01,\n",
       "       9.26077366e-03, 9.12798047e-01, 9.89697039e-01, 1.31532550e-02,\n",
       "       3.72141600e-03, 1.31532550e-02, 9.98884261e-01, 1.77296996e-02,\n",
       "       3.94022465e-03, 7.23522902e-03, 9.95093048e-01, 9.75515783e-01,\n",
       "       9.33557093e-01, 7.10821152e-03, 6.70576096e-03, 3.94022465e-03,\n",
       "       3.94022465e-03, 4.17745113e-03, 3.48573923e-03, 1.57018900e-02,\n",
       "       9.72275198e-01, 9.69457626e-03, 3.94022465e-03, 4.34076786e-03,\n",
       "       9.96530056e-04, 3.94022465e-03, 3.94022465e-03, 1.31532550e-02,\n",
       "       1.82723999e-03, 9.86743867e-01, 9.76816893e-01, 3.79866362e-03,\n",
       "       9.97309923e-01, 4.17745113e-03, 7.07243860e-01, 3.72141600e-03,\n",
       "       9.92371917e-01, 9.35715437e-03, 9.69457626e-03, 9.78846192e-01,\n",
       "       6.15692139e-03, 3.34936380e-03, 9.26077366e-03, 9.77682471e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict_proba(X_test)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
